{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of IMDB.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSVLV7xIwu4B",
        "outputId": "5ca48381-5417-41f8-cbc8-a48ee19b6691",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        }
      },
      "source": [
        "!wget -O IMDB.csv --no-check-certificate \"https://docs.google.com/uc?export=download&id=1LSuaWB1tL-x_F7qkAL8gq3giVZEq5OHv\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-20 18:08:32--  https://docs.google.com/uc?export=download&id=1LSuaWB1tL-x_F7qkAL8gq3giVZEq5OHv\n",
            "Resolving docs.google.com (docs.google.com)... 108.177.112.113, 108.177.112.139, 108.177.112.101, ...\n",
            "Connecting to docs.google.com (docs.google.com)|108.177.112.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-10-0k-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/c7sb1h2ej7e98cdpb4iudhfhpmas36l2/1603217250000/03223631635386730136/*/1LSuaWB1tL-x_F7qkAL8gq3giVZEq5OHv?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2020-10-20 18:08:39--  https://doc-10-0k-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/c7sb1h2ej7e98cdpb4iudhfhpmas36l2/1603217250000/03223631635386730136/*/1LSuaWB1tL-x_F7qkAL8gq3giVZEq5OHv?e=download\n",
            "Resolving doc-10-0k-docs.googleusercontent.com (doc-10-0k-docs.googleusercontent.com)... 172.217.214.132, 2607:f8b0:4001:c05::84\n",
            "Connecting to doc-10-0k-docs.googleusercontent.com (doc-10-0k-docs.googleusercontent.com)|172.217.214.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/csv]\n",
            "Saving to: ‘IMDB.csv’\n",
            "\n",
            "IMDB.csv                [   <=>              ]  63.14M   101MB/s    in 0.6s    \n",
            "\n",
            "2020-10-20 18:08:39 (101 MB/s) - ‘IMDB.csv’ saved [66212309]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bK6RAZx5447o",
        "outputId": "c5f90ef6-98db-40c8-8193-56cfb3b3b258",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "import pandas as pd \n",
        "df=pd.read_csv(\"IMDB.csv\")\n",
        "df.head(5)\n",
        "\n",
        "\n",
        "#positive.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AhZ-g7xVZqT",
        "outputId": "1d329f84-6e1d-4723-b3ae-8fd4a04f6531",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "positive =df['sentiment']=='positive'\n",
        "positiverows=df[positive]\n",
        "positiverows.head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKR7VnYzVeRr",
        "outputId": "3536114c-1c39-4ca5-9ff2-f52bd79c34b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "positive =df['sentiment']=='negative'\n",
        "positiverows=df[positive]\n",
        "positiverows.head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review sentiment\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "7  This show was an amazing, fresh & innovative i...  negative"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGtjsEH1aD9S",
        "outputId": "591e6328-34b2-4a74-dedf-cec3644c4170",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        }
      },
      "source": [
        "valuecounts=df['sentiment'].value_counts()\n",
        "valuecounts.head()\n",
        "valuecounts.plot(kind='bar')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fca88092e10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kz4WeqdakWET"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.corpus import stopwords\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "NB_WORDS = 10000  # Parameter indicating the number of words we'll put in the dictionary\n",
        "VAL_SIZE = 1000  # Size of the validation set\n",
        "NB_START_EPOCHS = 20  # Number of epochs we usually start to train with\n",
        "BATCH_SIZE = 128  # Size of the batches used in the mini-batch gradient descent\n",
        "MAX_LEN = 128  # Maximum number of words in a sequence\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXQwwALCk03Z"
      },
      "source": [
        "def deep_model(model, X_train, y_train, X_valid, y_valid):\n",
        "    '''\n",
        "    Function to train a multi-class model. The number of epochs and \n",
        "    batch_size are set by the constants at the top of the\n",
        "    notebook. \n",
        "    \n",
        "    Parameters:\n",
        "        model : model with the chosen architecture\n",
        "        X_train : training features\n",
        "        y_train : training target\n",
        "        X_valid : validation features\n",
        "        Y_valid : validation target\n",
        "    Output:\n",
        "        model training history\n",
        "    '''\n",
        "    model.compile(optimizer='rmsprop'\n",
        "                  , loss='categorical_crossentropy'\n",
        "                  , metrics=['accuracy'])\n",
        "    \n",
        "    history = model.fit(X_train\n",
        "                       , y_train\n",
        "                       , epochs=NB_START_EPOCHS\n",
        "                       , batch_size=BATCH_SIZE\n",
        "                       , validation_data=(X_valid, y_valid)\n",
        "                       , verbose=1)\n",
        "    return history\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def test_model(model, X_train, y_train, X_test, y_test, epoch_stop):\n",
        "    '''\n",
        "    Function to test the model on new data after training it\n",
        "    on the full training data with the optimal number of epochs.\n",
        "    \n",
        "    Parameters:\n",
        "        model : trained model\n",
        "        X_train : training features\n",
        "        y_train : training target\n",
        "        X_test : test features\n",
        "        y_test : test target\n",
        "        epochs : optimal number of epochs\n",
        "    Output:\n",
        "        test accuracy and test loss\n",
        "    '''\n",
        "    model.fit(X_train\n",
        "              , y_train\n",
        "              , epochs=epoch_stop\n",
        "              , batch_size=BATCH_SIZE\n",
        "              , verbose=0)\n",
        "    results = model.evaluate(X_test, y_test)\n",
        "    \n",
        "    return results\n",
        "\n",
        "def remove_stopwords(input_text):\n",
        "    '''\n",
        "    Function to remove English stopwords from a Pandas Series.\n",
        "    \n",
        "    Parameters:\n",
        "        input_text : text to clean\n",
        "    Output:\n",
        "        cleaned Pandas Series \n",
        "    '''\n",
        "    stopwords_list = stopwords.words('english')\n",
        "    # Some words which might indicate a certain sentiment are kept via a whitelist\n",
        "    whitelist = [\"n't\", \"not\", \"no\"]\n",
        "    input_text=cleanhtml(input_text)\n",
        "    words = input_text.split() \n",
        "    clean_words = [word for word in words if (word not in stopwords_list or word in whitelist) and len(word) > 1] \n",
        "    return \" \".join(clean_words) \n",
        "\n",
        "import re\n",
        "\n",
        "def cleanhtml(raw_html):\n",
        "  cleanr = re.compile('<.*?>')\n",
        "  cleantext = re.sub(cleanr, '', raw_html)\n",
        "  return str(cleantext)\n",
        "    \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jk1WMqaImpt6",
        "outputId": "ccef2bbe-d153-4db7-e880-83ae626e32b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "df = df.reindex(np.random.permutation(df.index))  \n",
        "df = df[['review', 'sentiment']]\n",
        "df.review = df.review.apply(remove_stopwords)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDfktjC7nN4t",
        "outputId": "b849fc3f-7f60-4c2d-cd0a-996c5a1a84af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df.review, df.sentiment, test_size=0.1, random_state=37)\n",
        "print('# Train data samples:', X_train.shape[0])\n",
        "print('# Test data samples:', X_test.shape[0])\n",
        "assert X_train.shape[0] == y_train.shape[0]\n",
        "assert X_test.shape[0] == y_test.shape[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# Train data samples: 45000\n",
            "# Test data samples: 5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-2d1p9mnbGm",
        "outputId": "b8a8adfe-6311-4804-f69b-e39882e6db2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tk = Tokenizer(num_words=NB_WORDS,\n",
        "               filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
        "               lower=True,\n",
        "               split=\" \")\n",
        "tk.fit_on_texts(X_train)\n",
        "\n",
        "X_train_seq = tk.texts_to_sequences(X_train)\n",
        "X_test_seq = tk.texts_to_sequences(X_test)\n",
        "len(X_train_seq)\n",
        "#X_test_seq[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "45000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywB9SbEAnmFS",
        "outputId": "ab0e5507-668d-46e3-b6e0-0c89de2706e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "seq_lengths = X_train.apply(lambda x: len(x.split(' ')))\n",
        "seq_lengths.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    45000.000000\n",
              "mean       129.808244\n",
              "std         97.004738\n",
              "min          4.000000\n",
              "25%         70.000000\n",
              "50%         97.000000\n",
              "75%        158.000000\n",
              "max       1501.000000\n",
              "Name: review, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbY_cnxenyDY",
        "outputId": "ba54639e-35d3-45e0-b34b-74bdf74f17f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        }
      },
      "source": [
        "X_train_seq_trunc = pad_sequences(X_train_seq,maxlen=MAX_LEN)\n",
        "X_test_seq_trunc = pad_sequences(X_test_seq,maxlen=MAX_LEN)\n",
        "X_train_seq_trunc[10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0, 8545,   86, 1074,\n",
              "       6017,  489, 9197,   81, 2190, 1810, 1965,  955, 7216, 2155, 8545,\n",
              "        106,  681,   46,  192,  965, 6827, 3287,  283,  114, 1234,  582,\n",
              "        469,  560,   31, 5584,   40,  247, 4216,  548,  476,    3,  151,\n",
              "       3714, 3015,  558, 1857,  154,   33,   31,   21, 2117, 2020,   26,\n",
              "       1660, 2361,  126, 6294, 6530, 3594, 1242,  331,  517, 8545,  333,\n",
              "         64,  232,   25,  648,  151,  837,  246, 1922, 1934,  117,    3,\n",
              "         19,  608,   29, 4714,    4,  327, 1248], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dJ559ZioWxC",
        "outputId": "28343d08-b837-4efb-c30d-df5bf99f0bac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "le = LabelEncoder()\n",
        "y_train_le = le.fit_transform(y_train)\n",
        "y_test_le = le.transform(y_test)\n",
        "y_train_oh = to_categorical(y_train_le,num_classes=2)\n",
        "y_test_oh = to_categorical(y_test_le,num_classes=2)\n",
        "print(y_train_le[0])\n",
        "print(y_train[0])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "positive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ml0d46ZUoc_7",
        "outputId": "8e143712-b0e9-41db-9537-c8bc1f63c0de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "X_train_emb, X_valid_emb, y_train_emb, y_valid_emb = train_test_split(X_train_seq_trunc, y_train_oh, test_size=0.1, random_state=37)\n",
        "\n",
        "assert X_valid_emb.shape[0] == y_valid_emb.shape[0]\n",
        "assert X_train_emb.shape[0] == y_train_emb.shape[0]\n",
        "\n",
        "print('Shape of validation X set:',X_valid_emb.shape)\n",
        "print('Shape of validation Y set:',y_valid_emb.shape)\n",
        "print('Shape of train Y set:', y_train_emb.shape)\n",
        "print('Shape of train X set:', X_train_emb.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of validation X set: (4500, 128)\n",
            "Shape of validation Y set: (4500, 2)\n",
            "Shape of train Y set: (40500, 2)\n",
            "Shape of train X set: (40500, 128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DBRMDK9ouaO",
        "outputId": "7d8c4f92-ea58-4875-febc-9b2d566d9d0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import tensorflow_hub as hub\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras import optimizers\n",
        "#from keras import models\n",
        "#from keras import layers\n",
        "#from keras import regularizers\n",
        "\n",
        "hub_layer = hub.KerasLayer(\"https://tfhub.dev/google/nnlm-en-dim128/2\",\n",
        "                           input_shape=[] ,dtype=tf.string,trainable=True)\n",
        "\n",
        "hub_layer(X_train)\n",
        "\n",
        "emb_model = Sequential()\n",
        "\n",
        "emb_model.add(layers.Embedding(NB_WORDS,4, input_length=MAX_LEN))\n",
        "emb_model.add(layers.Flatten())\n",
        "emb_model.add(layers.Dropout(0.3))\n",
        "emb_model.add(layers.Dense(16, activation = 'relu',kernel_regularizer = regularizers.l2(0.001)))\n",
        "#emb_model.add(layers.Dropout(0.2))\n",
        "#emb_model.add(layers.Dense(16, activation = 'relu',kernel_regularizer = regularizers.l2(0.001)))\n",
        "emb_model.add(layers.Dense(8, activation = 'relu',kernel_regularizer = regularizers.l2(0.001)))\n",
        "emb_model.add(layers.Dense(2, activation='softmax'))\n",
        "emb_model.compile(optimizer=optimizers.RMSprop(learning_rate=0.001,momentum=0)\n",
        "                  , loss='categorical_crossentropy'\n",
        "                  , metrics=['accuracy'])\n",
        "import time\n",
        "start_time = time.time()\n",
        "    \n",
        "emb_history = emb_model.fit(X_train_emb\n",
        "                       , y_train_emb\n",
        "                       , epochs=NB_START_EPOCHS\n",
        "                       , batch_size=BATCH_SIZE\n",
        "                       , validation_data=(X_valid_emb, y_valid_emb)\n",
        "                       , verbose=1)\n",
        "end_time = time.time()\n",
        "#emb_history = deep_model(emb_model, X_train_emb, y_train_emb, X_valid_emb, y_valid_emb)\n",
        "\n",
        "\n",
        "emb_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7fcaa4651bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7fcaa4651bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7fcaa464c158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7fcaa464c158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7fca9a8fab70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7fca9a8fab70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "317/317 [==============================] - 1s 5ms/step - loss: 0.5654 - accuracy: 0.7203 - val_loss: 0.3528 - val_accuracy: 0.8631\n",
            "Epoch 2/20\n",
            "317/317 [==============================] - 1s 4ms/step - loss: 0.3064 - accuracy: 0.8832 - val_loss: 0.2887 - val_accuracy: 0.8924\n",
            "Epoch 3/20\n",
            "317/317 [==============================] - 1s 4ms/step - loss: 0.2627 - accuracy: 0.9029 - val_loss: 0.2876 - val_accuracy: 0.8904\n",
            "Epoch 4/20\n",
            "317/317 [==============================] - 1s 4ms/step - loss: 0.2396 - accuracy: 0.9132 - val_loss: 0.2811 - val_accuracy: 0.8909\n",
            "Epoch 5/20\n",
            "317/317 [==============================] - 1s 4ms/step - loss: 0.2264 - accuracy: 0.9177 - val_loss: 0.2825 - val_accuracy: 0.8882\n",
            "Epoch 6/20\n",
            "317/317 [==============================] - 1s 4ms/step - loss: 0.2147 - accuracy: 0.9240 - val_loss: 0.2855 - val_accuracy: 0.8884\n",
            "Epoch 7/20\n",
            "317/317 [==============================] - 1s 4ms/step - loss: 0.2068 - accuracy: 0.9266 - val_loss: 0.2898 - val_accuracy: 0.8887\n",
            "Epoch 8/20\n",
            "317/317 [==============================] - 1s 4ms/step - loss: 0.1971 - accuracy: 0.9304 - val_loss: 0.2937 - val_accuracy: 0.8871\n",
            "Epoch 9/20\n",
            "317/317 [==============================] - 1s 4ms/step - loss: 0.1914 - accuracy: 0.9335 - val_loss: 0.2895 - val_accuracy: 0.8882\n",
            "Epoch 10/20\n",
            "317/317 [==============================] - 1s 4ms/step - loss: 0.1831 - accuracy: 0.9358 - val_loss: 0.2956 - val_accuracy: 0.8847\n",
            "Epoch 11/20\n",
            "317/317 [==============================] - 1s 4ms/step - loss: 0.1769 - accuracy: 0.9391 - val_loss: 0.2979 - val_accuracy: 0.8862\n",
            "Epoch 12/20\n",
            "317/317 [==============================] - 1s 4ms/step - loss: 0.1742 - accuracy: 0.9400 - val_loss: 0.3036 - val_accuracy: 0.8833\n",
            "Epoch 13/20\n",
            "317/317 [==============================] - 1s 4ms/step - loss: 0.1651 - accuracy: 0.9426 - val_loss: 0.3040 - val_accuracy: 0.8862\n",
            "Epoch 14/20\n",
            "317/317 [==============================] - 1s 4ms/step - loss: 0.1617 - accuracy: 0.9443 - val_loss: 0.3082 - val_accuracy: 0.8844\n",
            "Epoch 15/20\n",
            "317/317 [==============================] - 1s 4ms/step - loss: 0.1577 - accuracy: 0.9459 - val_loss: 0.3179 - val_accuracy: 0.8827\n",
            "Epoch 16/20\n",
            "317/317 [==============================] - 1s 4ms/step - loss: 0.1530 - accuracy: 0.9474 - val_loss: 0.3184 - val_accuracy: 0.8793\n",
            "Epoch 17/20\n",
            "317/317 [==============================] - 1s 4ms/step - loss: 0.1513 - accuracy: 0.9483 - val_loss: 0.3236 - val_accuracy: 0.8796\n",
            "Epoch 18/20\n",
            "317/317 [==============================] - 1s 4ms/step - loss: 0.1422 - accuracy: 0.9527 - val_loss: 0.3302 - val_accuracy: 0.8822\n",
            "Epoch 19/20\n",
            "317/317 [==============================] - 1s 4ms/step - loss: 0.1428 - accuracy: 0.9515 - val_loss: 0.3325 - val_accuracy: 0.8840\n",
            "Epoch 20/20\n",
            "317/317 [==============================] - 1s 4ms/step - loss: 0.1385 - accuracy: 0.9536 - val_loss: 0.3315 - val_accuracy: 0.8809\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_7 (Embedding)      (None, 128, 4)            40000     \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 16)                8208      \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 8)                 136       \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 2)                 18        \n",
            "=================================================================\n",
            "Total params: 48,362\n",
            "Trainable params: 48,362\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcsYfB8exEYc",
        "outputId": "4132e4d2-23b3-47c2-af39-1a99e0b1b026",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "time_taken =  end_time - start_time\n",
        "print(\"time_taken to train model :\", time_taken, \"seconds\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time_taken to train model : 26.623287200927734 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YFBpVRuqmK-"
      },
      "source": [
        "Hidden units were decided after trial and error basis, inclusion or reduction did not boost model performance . \n",
        "L2 regularization is added to all layers\n",
        "Dropout is added to the layer before relu activation to filter out unwanted properties. 0.30 value is added to force the output to be zero is the change is 30%\n",
        "Hidden layers use Relu function and Output layer uses softmax as the output is a probability"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ReqDebJsM8rG",
        "outputId": "96774f7f-6d79-445e-993d-377dbb845ee7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "emb_results = test_model(emb_model, X_train_seq_trunc, y_train_oh, X_test_seq_trunc, y_test_oh, 6)\n",
        "print('/n')\n",
        "print('Test accuracy of word embeddings model: {0:.2f}%'.format(emb_results[1]*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "157/157 [==============================] - 0s 1ms/step - loss: 0.3305 - accuracy: 0.8838\n",
            "/n\n",
            "Test accuracy of word embeddings model: 88.38%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lbBYSl0c9ZH",
        "outputId": "5d3483be-b214-4b5e-b483-ef18a2d0b064",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        }
      },
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "def eval_metric(history, metric_name):\n",
        "    '''\n",
        "    Function to evaluate a trained model on a chosen metric. \n",
        "    Training and validation metric are plotted in a\n",
        "    line chart for each epoch.\n",
        "    \n",
        "    Parameters:\n",
        "        history : model training history\n",
        "        metric_name : loss or accuracy\n",
        "    Output:\n",
        "        line chart with epochs of x-axis and metric on\n",
        "        y-axis\n",
        "    '''\n",
        "    metric = history.history[metric_name]\n",
        "    val_metric = history.history['val_' + metric_name]\n",
        "\n",
        "    e = range(1, NB_START_EPOCHS + 1)\n",
        "\n",
        "    plt.plot(e, metric, 'bo', label='Train ' + metric_name)\n",
        "    plt.plot(e, val_metric, 'b', label='Validation ' + metric_name)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "eval_metric(emb_history, 'accuracy')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzoDZ4OHePrj",
        "outputId": "9a3c34fb-be26-4053-a3d1-467523473da4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        }
      },
      "source": [
        "eval_metric(emb_history, 'loss')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEN7SNwl0Og-",
        "outputId": "650b1a2d-5ec8-47e5-deba-0aba49af6dc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "preds=np.argmax(emb_model.predict(X_test_seq_trunc),axis=-1)\n",
        "#print(preds)\n",
        "#print(y_test_le)\n",
        "cf_matrix =confusion_matrix(y_test_le,preds)\n",
        "print(cf_matrix)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2254  295]\n",
            " [ 286 2165]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZXWa0E2bwRQ",
        "outputId": "a883efb8-7ac2-495c-ad13-606e1d8a9466",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "import seaborn as sns\n",
        "#sns.heatmap(cf_matrix, annot=True)\n",
        "labels = ['True Neg','False Pos','False Neg','True Pos']\n",
        "labels = np.asarray(labels).reshape(2,2)\n",
        "sns.heatmap(cf_matrix, annot=labels, fmt='', cmap='Blues')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fcaa48b3e80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeBX_Xtpr9pH",
        "outputId": "686594c6-75dd-4889-e370-6e996cdb4e0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_true= y_test_le, y_pred=preds))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.88      0.89      2549\n",
            "           1       0.88      0.88      0.88      2451\n",
            "\n",
            "    accuracy                           0.88      5000\n",
            "   macro avg       0.88      0.88      0.88      5000\n",
            "weighted avg       0.88      0.88      0.88      5000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKrGWvF7tPBT"
      },
      "source": [
        "Both the classes (0-> positive and 1-negetive) are approximately equally classified and missclassified .It might be due to ambiguous statements in the data . "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFps5OKzto7P"
      },
      "source": [
        "**HYPERPARAMATER TUNING **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPVFJaADi00s",
        "outputId": "3807bd43-d5a7-4493-f314-fb496937c43c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "## CHANGED BATCH SIZE->64 IN THIS HYPERPARAMETER TUNING\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import regularizers\n",
        "#from keras import models\n",
        "#from keras import layers\n",
        "#from keras import regularizers\n",
        "\n",
        "\n",
        "\n",
        "emb_model = Sequential()\n",
        "\n",
        "emb_model.add(layers.Embedding(NB_WORDS,4, input_length=MAX_LEN))\n",
        "emb_model.add(layers.Flatten())\n",
        "emb_model.add(layers.Dropout(0.3))\n",
        "emb_model.add(layers.Dense(16, activation = 'relu',kernel_regularizer = regularizers.l2(0.001)))\n",
        "#emb_model.add(layers.Dropout(0.2))\n",
        "#emb_model.add(layers.Dense(30, activation = 'relu',kernel_regularizer = regularizers.l2(0.001)))\n",
        "emb_model.add(layers.Dense(8, activation = 'relu',kernel_regularizer = regularizers.l2(0.001)))\n",
        "emb_model.add(layers.Dense(2, activation='softmax'))\n",
        "emb_model.compile(optimizer=optimizers.RMSprop(learning_rate=0.001,momentum=0)\n",
        "                  , loss='categorical_crossentropy'\n",
        "                  , metrics=['accuracy'])\n",
        "import time\n",
        "start_time = time.time()\n",
        "    \n",
        "emb_history = emb_model.fit(X_train_emb\n",
        "                       , y_train_emb\n",
        "                       , epochs=NB_START_EPOCHS\n",
        "                       , batch_size=64\n",
        "                       , validation_data=(X_valid_emb, y_valid_emb)\n",
        "                       , verbose=1)\n",
        "end_time = time.time()\n",
        "#emb_history = deep_model(emb_model, X_train_emb, y_train_emb, X_valid_emb, y_valid_emb)\n",
        "\n",
        "\n",
        "emb_model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7fca88989620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7fca88989620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7fcaa3a15510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7fcaa3a15510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "633/633 [==============================] - 2s 3ms/step - loss: 0.5056 - accuracy: 0.7492 - val_loss: 0.3144 - val_accuracy: 0.8776\n",
            "Epoch 2/20\n",
            "633/633 [==============================] - 2s 3ms/step - loss: 0.2947 - accuracy: 0.8867 - val_loss: 0.2834 - val_accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "633/633 [==============================] - 2s 3ms/step - loss: 0.2562 - accuracy: 0.9038 - val_loss: 0.2806 - val_accuracy: 0.8931\n",
            "Epoch 4/20\n",
            "633/633 [==============================] - 2s 3ms/step - loss: 0.2329 - accuracy: 0.9160 - val_loss: 0.2844 - val_accuracy: 0.8907\n",
            "Epoch 5/20\n",
            "633/633 [==============================] - 2s 3ms/step - loss: 0.2183 - accuracy: 0.9221 - val_loss: 0.2870 - val_accuracy: 0.8900\n",
            "Epoch 6/20\n",
            "633/633 [==============================] - 2s 3ms/step - loss: 0.2084 - accuracy: 0.9257 - val_loss: 0.2926 - val_accuracy: 0.8898\n",
            "Epoch 7/20\n",
            "633/633 [==============================] - 2s 3ms/step - loss: 0.1977 - accuracy: 0.9299 - val_loss: 0.2972 - val_accuracy: 0.8864\n",
            "Epoch 8/20\n",
            "633/633 [==============================] - 2s 3ms/step - loss: 0.1904 - accuracy: 0.9313 - val_loss: 0.2986 - val_accuracy: 0.8876\n",
            "Epoch 9/20\n",
            "633/633 [==============================] - 2s 3ms/step - loss: 0.1846 - accuracy: 0.9340 - val_loss: 0.3044 - val_accuracy: 0.8873\n",
            "Epoch 10/20\n",
            "633/633 [==============================] - 2s 3ms/step - loss: 0.1774 - accuracy: 0.9378 - val_loss: 0.3117 - val_accuracy: 0.8804\n",
            "Epoch 11/20\n",
            "633/633 [==============================] - 2s 3ms/step - loss: 0.1739 - accuracy: 0.9384 - val_loss: 0.3112 - val_accuracy: 0.8838\n",
            "Epoch 12/20\n",
            "633/633 [==============================] - 2s 3ms/step - loss: 0.1675 - accuracy: 0.9411 - val_loss: 0.3227 - val_accuracy: 0.8784\n",
            "Epoch 13/20\n",
            "633/633 [==============================] - 2s 3ms/step - loss: 0.1644 - accuracy: 0.9425 - val_loss: 0.3172 - val_accuracy: 0.8782\n",
            "Epoch 14/20\n",
            "633/633 [==============================] - 2s 3ms/step - loss: 0.1609 - accuracy: 0.9432 - val_loss: 0.3213 - val_accuracy: 0.8847\n",
            "Epoch 15/20\n",
            "633/633 [==============================] - 2s 3ms/step - loss: 0.1577 - accuracy: 0.9447 - val_loss: 0.3237 - val_accuracy: 0.8816\n",
            "Epoch 16/20\n",
            "633/633 [==============================] - 2s 3ms/step - loss: 0.1560 - accuracy: 0.9447 - val_loss: 0.3285 - val_accuracy: 0.8791\n",
            "Epoch 17/20\n",
            "633/633 [==============================] - 2s 3ms/step - loss: 0.1512 - accuracy: 0.9472 - val_loss: 0.3286 - val_accuracy: 0.8769\n",
            "Epoch 18/20\n",
            "633/633 [==============================] - 2s 3ms/step - loss: 0.1492 - accuracy: 0.9479 - val_loss: 0.3296 - val_accuracy: 0.8764\n",
            "Epoch 19/20\n",
            "633/633 [==============================] - 2s 3ms/step - loss: 0.1496 - accuracy: 0.9482 - val_loss: 0.3348 - val_accuracy: 0.8769\n",
            "Epoch 20/20\n",
            "633/633 [==============================] - 2s 3ms/step - loss: 0.1443 - accuracy: 0.9499 - val_loss: 0.3357 - val_accuracy: 0.8771\n",
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_8 (Embedding)      (None, 128, 4)            40000     \n",
            "_________________________________________________________________\n",
            "flatten_8 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 16)                8208      \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 8)                 136       \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 2)                 18        \n",
            "=================================================================\n",
            "Total params: 48,362\n",
            "Trainable params: 48,362\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JA1rTuovyMBv",
        "outputId": "a222cb00-9c28-49d9-b39d-8f8868bc7033",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "results = emb_model.evaluate(X_test_seq_trunc, y_test_oh)\n",
        "print('/n')\n",
        "print('Test accuracy of word embeddings model: {0:.2f}%'.format(emb_results[1]*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "157/157 [==============================] - 0s 1ms/step - loss: 0.3359 - accuracy: 0.8844\n",
            "/n\n",
            "Test accuracy of word embeddings model: 88.38%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BdKlWhqzANN",
        "outputId": "0fa01783-cfc1-4437-82b7-12433ec5aefe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "## CHANGED LEARNING RATE  IN THIS HYPERPARAMETER TUNING KEEPING BATCH SIZE 64\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import regularizers\n",
        "#from keras import models\n",
        "#from keras import layers\n",
        "#from keras import regularizers\n",
        "\n",
        "hub_layer = hub.KerasLayer(\"https://tfhub.dev/google/nnlm-en-dim128/2\",\n",
        "                           input_shape=[] ,dtype=tf.string,trainable=True)\n",
        "\n",
        "hub_layer(X_train)\n",
        "\n",
        "emb_model = Sequential()\n",
        "\n",
        "emb_model.add(layers.Embedding(NB_WORDS,4, input_length=MAX_LEN))\n",
        "emb_model.add(layers.Flatten())\n",
        "emb_model.add(layers.Dropout(0.3))\n",
        "emb_model.add(layers.Dense(16, activation = 'relu',kernel_regularizer = regularizers.l2(0.001)))\n",
        "#emb_model.add(layers.Dropout(0.2))\n",
        "#emb_model.add(layers.Dense(30, activation = 'relu',kernel_regularizer = regularizers.l2(0.001)))\n",
        "emb_model.add(layers.Dense(8, activation = 'relu',kernel_regularizer = regularizers.l2(0.001)))\n",
        "emb_model.add(layers.Dense(2, activation='softmax'))\n",
        "emb_model.compile(optimizer=optimizers.RMSprop(learning_rate=0.01,momentum=0)\n",
        "                  , loss='categorical_crossentropy'\n",
        "                  , metrics=['accuracy'])\n",
        "import time\n",
        "start_time = time.time()\n",
        "    \n",
        "emb_history = emb_model.fit(X_train_emb\n",
        "                       , y_train_emb\n",
        "                       , epochs=NB_START_EPOCHS\n",
        "                       , batch_size=64\n",
        "                       , validation_data=(X_valid_emb, y_valid_emb)\n",
        "                       , verbose=1)\n",
        "end_time = time.time()\n",
        "#emb_history = deep_model(emb_model, X_train_emb, y_train_emb, X_valid_emb, y_valid_emb)\n",
        "\n",
        "\n",
        "emb_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7fca880fa510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7fca880fa510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7fca88158a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7fca88158a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7fca8ea03b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7fca8ea03b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "633/633 [==============================] - 2s 3ms/step - loss: 0.3930 - accuracy: 0.8353 - val_loss: 0.3106 - val_accuracy: 0.8807\n",
            "Epoch 2/20\n",
            "633/633 [==============================] - 2s 3ms/step - loss: 0.2848 - accuracy: 0.8946 - val_loss: 0.2965 - val_accuracy: 0.8900\n",
            "Epoch 3/20\n",
            "633/633 [==============================] - 2s 3ms/step - loss: 0.2594 - accuracy: 0.9057 - val_loss: 0.3005 - val_accuracy: 0.8880\n",
            "Epoch 4/20\n",
            "633/633 [==============================] - 2s 3ms/step - loss: 0.2434 - accuracy: 0.9125 - val_loss: 0.3054 - val_accuracy: 0.8862\n",
            "Epoch 5/20\n",
            "633/633 [==============================] - 2s 3ms/step - loss: 0.2326 - accuracy: 0.9177 - val_loss: 0.3143 - val_accuracy: 0.8807\n",
            "Epoch 6/20\n",
            "633/633 [==============================] - 2s 3ms/step - loss: 0.2254 - accuracy: 0.9207 - val_loss: 0.3135 - val_accuracy: 0.8876\n",
            "Epoch 7/20\n",
            "633/633 [==============================] - 2s 3ms/step - loss: 0.2209 - accuracy: 0.9229 - val_loss: 0.2970 - val_accuracy: 0.8851\n",
            "Epoch 8/20\n",
            "633/633 [==============================] - 2s 3ms/step - loss: 0.2135 - accuracy: 0.9269 - val_loss: 0.3209 - val_accuracy: 0.8787\n",
            "Epoch 9/20\n",
            "633/633 [==============================] - 2s 3ms/step - loss: 0.2105 - accuracy: 0.9279 - val_loss: 0.3145 - val_accuracy: 0.8827\n",
            "Epoch 10/20\n",
            "633/633 [==============================] - 2s 3ms/step - loss: 0.2074 - accuracy: 0.9310 - val_loss: 0.3146 - val_accuracy: 0.8833\n",
            "Epoch 11/20\n",
            "633/633 [==============================] - 2s 3ms/step - loss: 0.2020 - accuracy: 0.9312 - val_loss: 0.3225 - val_accuracy: 0.8798\n",
            "Epoch 12/20\n",
            "633/633 [==============================] - 2s 3ms/step - loss: 0.1953 - accuracy: 0.9352 - val_loss: 0.3285 - val_accuracy: 0.8778\n",
            "Epoch 13/20\n",
            "633/633 [==============================] - 2s 3ms/step - loss: 0.1921 - accuracy: 0.9347 - val_loss: 0.3223 - val_accuracy: 0.8791\n",
            "Epoch 14/20\n",
            "633/633 [==============================] - 2s 3ms/step - loss: 0.1922 - accuracy: 0.9358 - val_loss: 0.3158 - val_accuracy: 0.8793\n",
            "Epoch 15/20\n",
            "633/633 [==============================] - 2s 3ms/step - loss: 0.1895 - accuracy: 0.9370 - val_loss: 0.3227 - val_accuracy: 0.8778\n",
            "Epoch 16/20\n",
            "633/633 [==============================] - 2s 3ms/step - loss: 0.1835 - accuracy: 0.9395 - val_loss: 0.3286 - val_accuracy: 0.8798\n",
            "Epoch 17/20\n",
            "633/633 [==============================] - 2s 3ms/step - loss: 0.1818 - accuracy: 0.9418 - val_loss: 0.3371 - val_accuracy: 0.8731\n",
            "Epoch 18/20\n",
            "633/633 [==============================] - 2s 3ms/step - loss: 0.1798 - accuracy: 0.9425 - val_loss: 0.3465 - val_accuracy: 0.8780\n",
            "Epoch 19/20\n",
            "633/633 [==============================] - 2s 3ms/step - loss: 0.1842 - accuracy: 0.9403 - val_loss: 0.3405 - val_accuracy: 0.8809\n",
            "Epoch 20/20\n",
            "633/633 [==============================] - 2s 3ms/step - loss: 0.1776 - accuracy: 0.9420 - val_loss: 0.3249 - val_accuracy: 0.8764\n",
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_9 (Embedding)      (None, 128, 4)            40000     \n",
            "_________________________________________________________________\n",
            "flatten_9 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 16)                8208      \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 8)                 136       \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 2)                 18        \n",
            "=================================================================\n",
            "Total params: 48,362\n",
            "Trainable params: 48,362\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEY8eIxb6AAt",
        "outputId": "d61ef7d9-7acd-4079-9c23-26e1f59cfd1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "results = emb_model.evaluate(X_test_seq_trunc, y_test_oh)\n",
        "print('/n')\n",
        "print('Test accuracy of word embeddings model: {0:.2f}%'.format(results[1]*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "157/157 [==============================] - 0s 1ms/step - loss: 0.3258 - accuracy: 0.8850\n",
            "/n\n",
            "Test accuracy of word embeddings model: 88.50%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jl_YdpKm6Ht5",
        "outputId": "27bc5e24-7b5a-4c9e-ea4e-152bfbc93f49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "## CHANGED LEARNING RATE  IN THIS HYPERPARAMETER TUNING KEEPING BATCH SIZE 64 AND training without regularisation\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import regularizers\n",
        "#from keras import models\n",
        "#from keras import layers\n",
        "#from keras import regularizers\n",
        "\n",
        "hub_layer = hub.KerasLayer(\"https://tfhub.dev/google/nnlm-en-dim128/2\",\n",
        "                           input_shape=[] ,dtype=tf.string,trainable=True)\n",
        "\n",
        "hub_layer(X_train)\n",
        "\n",
        "emb_model = Sequential()\n",
        "\n",
        "emb_model.add(layers.Embedding(NB_WORDS,4, input_length=MAX_LEN))\n",
        "emb_model.add(layers.Flatten())\n",
        "emb_model.add(layers.Dropout(0.3))\n",
        "emb_model.add(layers.Dense(60, activation = 'relu'))\n",
        "#emb_model.add(layers.Dropout(0.2))\n",
        "emb_model.add(layers.Dense(30, activation = 'relu'))\n",
        "emb_model.add(layers.Dense(16, activation = 'relu'))\n",
        "emb_model.add(layers.Dense(2, activation='softmax'))\n",
        "emb_model.compile(optimizer=optimizers.RMSprop(learning_rate=0.01,momentum=0)\n",
        "                  , loss='categorical_crossentropy'\n",
        "                  , metrics=['accuracy'])\n",
        "import time\n",
        "start_time = time.time()\n",
        "    \n",
        "emb_history = emb_model.fit(X_train_emb\n",
        "                       , y_train_emb\n",
        "                       , epochs=NB_START_EPOCHS\n",
        "                       , batch_size=64\n",
        "                       , validation_data=(X_valid_emb, y_valid_emb)\n",
        "                       , verbose=1)\n",
        "end_time = time.time()\n",
        "#emb_history = deep_model(emb_model, X_train_emb, y_train_emb, X_valid_emb, y_valid_emb)\n",
        "\n",
        "\n",
        "emb_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7fca99af4378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7fca99af4378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7fca99af4840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7fca99af4840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7fca99aef400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7fca99aef400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "633/633 [==============================] - 2s 4ms/step - loss: 0.3859 - accuracy: 0.8178 - val_loss: 0.2737 - val_accuracy: 0.8851\n",
            "Epoch 2/20\n",
            "633/633 [==============================] - 2s 3ms/step - loss: 0.2640 - accuracy: 0.8942 - val_loss: 0.2704 - val_accuracy: 0.8856\n",
            "Epoch 3/20\n",
            "633/633 [==============================] - 2s 3ms/step - loss: 0.2276 - accuracy: 0.9106 - val_loss: 0.2908 - val_accuracy: 0.8816\n",
            "Epoch 4/20\n",
            "633/633 [==============================] - 2s 3ms/step - loss: 0.2059 - accuracy: 0.9212 - val_loss: 0.2905 - val_accuracy: 0.8849\n",
            "Epoch 5/20\n",
            "633/633 [==============================] - 2s 3ms/step - loss: 0.1927 - accuracy: 0.9266 - val_loss: 0.2899 - val_accuracy: 0.8902\n",
            "Epoch 6/20\n",
            "633/633 [==============================] - 2s 3ms/step - loss: 0.1798 - accuracy: 0.9327 - val_loss: 0.2902 - val_accuracy: 0.8831\n",
            "Epoch 7/20\n",
            "633/633 [==============================] - 2s 3ms/step - loss: 0.1691 - accuracy: 0.9380 - val_loss: 0.3303 - val_accuracy: 0.8811\n",
            "Epoch 8/20\n",
            "633/633 [==============================] - 2s 3ms/step - loss: 0.1665 - accuracy: 0.9386 - val_loss: 0.3088 - val_accuracy: 0.8802\n",
            "Epoch 9/20\n",
            "633/633 [==============================] - 2s 3ms/step - loss: 0.1562 - accuracy: 0.9446 - val_loss: 0.3082 - val_accuracy: 0.8782\n",
            "Epoch 10/20\n",
            "633/633 [==============================] - 2s 3ms/step - loss: 0.1499 - accuracy: 0.9465 - val_loss: 0.3830 - val_accuracy: 0.8778\n",
            "Epoch 11/20\n",
            "633/633 [==============================] - 2s 3ms/step - loss: 0.1475 - accuracy: 0.9475 - val_loss: 0.3117 - val_accuracy: 0.8782\n",
            "Epoch 12/20\n",
            "633/633 [==============================] - 2s 3ms/step - loss: 0.1452 - accuracy: 0.9503 - val_loss: 0.3486 - val_accuracy: 0.8776\n",
            "Epoch 13/20\n",
            "633/633 [==============================] - 2s 3ms/step - loss: 0.1386 - accuracy: 0.9508 - val_loss: 0.3715 - val_accuracy: 0.8684\n",
            "Epoch 14/20\n",
            "633/633 [==============================] - 2s 3ms/step - loss: 0.1338 - accuracy: 0.9538 - val_loss: 0.3641 - val_accuracy: 0.8713\n",
            "Epoch 15/20\n",
            "633/633 [==============================] - 2s 3ms/step - loss: 0.1358 - accuracy: 0.9539 - val_loss: 0.4791 - val_accuracy: 0.8742\n",
            "Epoch 16/20\n",
            "633/633 [==============================] - 2s 3ms/step - loss: 0.1421 - accuracy: 0.9530 - val_loss: 0.3860 - val_accuracy: 0.8742\n",
            "Epoch 17/20\n",
            "633/633 [==============================] - 2s 3ms/step - loss: 0.1330 - accuracy: 0.9560 - val_loss: 1.1872 - val_accuracy: 0.8742\n",
            "Epoch 18/20\n",
            "633/633 [==============================] - 2s 3ms/step - loss: 0.1525 - accuracy: 0.9563 - val_loss: 0.4749 - val_accuracy: 0.8680\n",
            "Epoch 19/20\n",
            "633/633 [==============================] - 2s 3ms/step - loss: 0.1320 - accuracy: 0.9579 - val_loss: 0.4109 - val_accuracy: 0.8722\n",
            "Epoch 20/20\n",
            "633/633 [==============================] - 2s 3ms/step - loss: 0.1272 - accuracy: 0.9580 - val_loss: 0.7485 - val_accuracy: 0.8629\n",
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_10 (Embedding)     (None, 128, 4)            40000     \n",
            "_________________________________________________________________\n",
            "flatten_10 (Flatten)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 60)                30780     \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 30)                1830      \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 16)                496       \n",
            "_________________________________________________________________\n",
            "dense_29 (Dense)             (None, 2)                 34        \n",
            "=================================================================\n",
            "Total params: 73,140\n",
            "Trainable params: 73,140\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zDuQuMC6rg9",
        "outputId": "c8a38e8e-844f-4b6c-ed59-910fbdb407c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "results = emb_model.evaluate(X_test_seq_trunc, y_test_oh)\n",
        "print('/n')\n",
        "print('Test accuracy of word embeddings model: {0:.2f}%'.format(results[1]*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "157/157 [==============================] - 0s 1ms/step - loss: 0.6626 - accuracy: 0.8690\n",
            "/n\n",
            "Test accuracy of word embeddings model: 86.90%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wam4b0zPL7xe"
      },
      "source": [
        "**MODEL CREATION USING PRETRAINED WEIGHTS **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnuhIy7TxNYc",
        "outputId": "d17f1d96-c661-47c4-bd3a-4b729faeffb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 890
        }
      },
      "source": [
        "\n",
        "\n",
        "hub_layer = hub.KerasLayer(\"https://tfhub.dev/google/nnlm-en-dim128/2\",\n",
        "                           input_shape=[], dtype=tf.string)\n",
        "\n",
        "# if I add hub layer then i get shape error ,\n",
        "#embedded = hub_layer(tf.reshape(df.review[:10000]))\n",
        "embedded=hub_layer(df.review[:10000])\n",
        "#embedded=tf.reshape(embedded,[:4])\n",
        "#embedded = hub_layer(df.review[:10000])\n",
        "print(embedded)\n",
        "embedding_layer = layers.Embedding(10000,\n",
        "                            128,\n",
        "                            weights=[embedded],\n",
        "                            input_length=MAX_LEN,\n",
        "                            trainable=False)\n",
        "\n",
        "emb_model = Sequential()\n",
        "emb_model.add(embedding_layer)\n",
        "emb_model.add(layers.Flatten())\n",
        "emb_model.add(layers.Dropout(0.3))\n",
        "emb_model.add(layers.Dense(8, activation = 'relu'))\n",
        "emb_model.add(layers.Dense(2, activation='softmax'))\n",
        "emb_model.compile(optimizer=optimizers.RMSprop(learning_rate=0.01,momentum=.25)\n",
        "                  , loss='categorical_crossentropy'\n",
        "                  , metrics=['accuracy'])\n",
        "import time\n",
        "start_time = time.time()\n",
        "    \n",
        "emb_history = emb_model.fit(X_train_emb\n",
        "                       , y_train_emb\n",
        "                       , epochs=5\n",
        "                       , batch_size=64\n",
        "                       , validation_data=(X_valid_emb, y_valid_emb)\n",
        "                       , verbose=1)\n",
        "end_time = time.time()\n",
        "#emb_history = deep_model(emb_model, X_train_emb, y_train_emb, X_valid_emb, y_valid_emb)\n",
        "\n",
        "\n",
        "emb_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7fcaa3ac5620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7fcaa3ac5620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7fcaa3ac5b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7fcaa3ac5b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7fca8d6c5c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7fca8d6c5c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[ 0.2286596   0.1567697   0.04163042 ... -0.05484968  0.09114031\n",
            "   0.18645424]\n",
            " [ 0.24344252 -0.00834238  0.09855147 ... -0.34181222  0.14829344\n",
            "   0.2064092 ]\n",
            " [ 0.28259435  0.10403575  0.09568932 ... -0.17417295  0.15409155\n",
            "   0.11913329]\n",
            " ...\n",
            " [-0.24940245  0.10744675  0.01557767 ... -0.07574641  0.0377127\n",
            "   0.02313053]\n",
            " [-0.03606247  0.07361308 -0.05847034 ... -0.3309123   0.08151184\n",
            "  -0.1181119 ]\n",
            " [ 0.25184613  0.06969944 -0.03010845 ... -0.48930988  0.33697847\n",
            "   0.18310215]], shape=(10000, 128), dtype=float32)\n",
            "Epoch 1/5\n",
            "633/633 [==============================] - 14s 22ms/step - loss: 0.7393 - accuracy: 0.5013 - val_loss: 0.6946 - val_accuracy: 0.4960\n",
            "Epoch 2/5\n",
            "633/633 [==============================] - 13s 21ms/step - loss: 0.6935 - accuracy: 0.5001 - val_loss: 0.6932 - val_accuracy: 0.5040\n",
            "Epoch 3/5\n",
            "633/633 [==============================] - 13s 21ms/step - loss: 0.6935 - accuracy: 0.5023 - val_loss: 0.6934 - val_accuracy: 0.4960\n",
            "Epoch 4/5\n",
            "633/633 [==============================] - 13s 21ms/step - loss: 0.6935 - accuracy: 0.5021 - val_loss: 0.6931 - val_accuracy: 0.5040\n",
            "Epoch 5/5\n",
            "633/633 [==============================] - 13s 21ms/step - loss: 0.6937 - accuracy: 0.4976 - val_loss: 0.6931 - val_accuracy: 0.5040\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_6 (Embedding)      (None, 128, 128)          1280000   \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 16384)             0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 16384)             0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 8)                 131080    \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 2)                 18        \n",
            "=================================================================\n",
            "Total params: 1,411,098\n",
            "Trainable params: 131,098\n",
            "Non-trainable params: 1,280,000\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSGG6SXZ1aHu",
        "outputId": "461a70fc-41fe-4d75-f80b-74ff1ce0eb01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "#emb_results = test_model(emb_model, X_train_seq_trunc, y_train_oh, X_test_seq_trunc, y_test_oh, 6)\n",
        "\n",
        "results = emb_model.evaluate(X_test_seq_trunc, y_test_oh)\n",
        "print('/n')\n",
        "print('Test accuracy of word embeddings model: {0:.2f}%'.format(results[1]*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "157/157 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.4980\n",
            "/n\n",
            "Test accuracy of word embeddings model: 49.80%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}